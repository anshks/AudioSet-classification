{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a924ee45-219f-4646-8830-77c5675ee1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c300cf-e4e9-4042-9f37-ed2880f0d96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54617711/ipykernel_1069390/3713021574.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/train_rep.pt\")\n",
      "/state/partition1/job-54617711/ipykernel_1069390/3713021574.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/labels.pt\")\n",
      "/state/partition1/job-54617711/ipykernel_1069390/3713021574.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/test_rep.pt\")\n",
      "/state/partition1/job-54617711/ipykernel_1069390/3713021574.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/labels.pt\")\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/train_rep.pt\")\n",
    "y_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/labels.pt\")\n",
    "x_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/test_rep.pt\")\n",
    "y_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b560f2fc-d544-4289-80c6-a9c63940b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stratified_split(x_data, y_data, random_state=42):\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    indices = np.arange(len(y_data))\n",
    "    for train_idx, val_idx in mskf.split(indices, y_data):\n",
    "        return train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ecffa6-e9a6-43ad-84a5-ae6d13209ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(y_true, y_pred):\n",
    "    n_classes = y_true.shape[1]\n",
    "    average_precisions = []\n",
    "    for i in range(n_classes):\n",
    "        y_true_class = y_true[:, i]\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        ap = average_precision_score(y_true_class, y_pred_class)\n",
    "        average_precisions.append(ap)\n",
    "    average_precisions_sorted = sorted(average_precisions, reverse=True)\n",
    "    print(\"\\nTop 5 class-wise Average Precisions:\")\n",
    "    for i, ap in enumerate(average_precisions_sorted[:5]):\n",
    "        print(f\"Class {i+1}: {ap:.4f}\")\n",
    "    \n",
    "    return np.mean(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1aa17c7-4d9f-4b4b-bfd3-6c9e39a0afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    print(\"Model being trained: \", model.__class__.__name__)\n",
    "    model = model.to(device)\n",
    "    best_map = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float().to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_targets.extend(batch_y.cpu().numpy())\n",
    "        \n",
    "        # lists -> numpy arrays for metric calculation\n",
    "        val_predictions = np.array(val_predictions)\n",
    "        val_targets = np.array(val_targets)\n",
    "        val_map = calculate_map(val_targets, val_predictions)\n",
    "        val_f1 = f1_score(val_targets, (val_predictions > 0.5).astype(float), average='micro')\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "        print(f'Validation MAP: {val_map:.4f}')\n",
    "        print(f'Validation F1-Score: {val_f1:.4f}')\n",
    "        \n",
    "        # Save best model based on MAP\n",
    "        if val_map > best_map:\n",
    "            best_map = val_map\n",
    "            model_name = model.__class__.__name__ \n",
    "            filename = f\"best_{model_name}_map_lastlayer.pth\"\n",
    "            torch.save(model.state_dict(), filename)\n",
    "            print(f\"New best model saved as {filename}!\")\n",
    "        \n",
    "        print('-' * 50)\n",
    "    return model, best_map  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb76774-918e-4f92-ae9f-f671215ad5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device='cuda'):\n",
    "    print(\"Model being tested: \", model.__class__.__name__)\n",
    "    test_dataset = TensorDataset(x_test.float(), y_test.float())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model.load_state_dict(torch.load(\"best_CNNClassifier_map_lastlayer.pth\"))\n",
    "    model.eval()\n",
    "    \n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            outputs = model(batch_x)\n",
    "            test_predictions.extend(outputs.cpu().numpy())\n",
    "            test_targets.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    test_predictions = np.array(test_predictions)\n",
    "    test_targets = np.array(test_targets)\n",
    "    \n",
    "    test_map = calculate_map(test_targets, test_predictions)\n",
    "    test_f1 = f1_score(test_targets, (test_predictions > 0.5).astype(float), average=\"micro\")\n",
    "    \n",
    "    print(f\"Test MAP: {test_map:.4f}\")\n",
    "    print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "    \n",
    "    return test_map, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e906b68-439b-4572-b17a-f25fea1df6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_channels=768, num_classes=527):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )   \n",
    "        # Second Convolutional Block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        # Third Convolutional Block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.flatten_size = 64 * (496 // (2*2*2))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f7b816-c6d2-4edb-a95d-eb1518f794f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate= 0.001\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x_train_float = x_train.float()\n",
    "y_train_float = y_train.float()\n",
    "full_dataset = TensorDataset(x_train_float, y_train_float)\n",
    "total_size = len(full_dataset)\n",
    "\n",
    "train_indices, val_indices = create_stratified_split(x_train_float, y_train_float.numpy())\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68661b2d-cb08-4771-8c33-e3830b5286b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model being trained:  CNNClassifier\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 0.9447\n",
      "Class 2: 0.8276\n",
      "Class 3: 0.8101\n",
      "Class 4: 0.7707\n",
      "Class 5: 0.7667\n",
      "\n",
      "Epoch 1/10:\n",
      "Training Loss: 0.0285\n",
      "Validation Loss: 0.0187\n",
      "Validation MAP: 0.1283\n",
      "Validation F1-Score: 0.2761\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 0.9124\n",
      "Class 2: 0.8931\n",
      "Class 3: 0.8873\n",
      "Class 4: 0.8872\n",
      "Class 5: 0.8826\n",
      "\n",
      "Epoch 2/10:\n",
      "Training Loss: 0.0185\n",
      "Validation Loss: 0.0157\n",
      "Validation MAP: 0.2471\n",
      "Validation F1-Score: 0.2950\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 1.0000\n",
      "Class 2: 0.9429\n",
      "Class 3: 0.9310\n",
      "Class 4: 0.9210\n",
      "Class 5: 0.8838\n",
      "\n",
      "Epoch 3/10:\n",
      "Training Loss: 0.0161\n",
      "Validation Loss: 0.0148\n",
      "Validation MAP: 0.3029\n",
      "Validation F1-Score: 0.3532\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 1.0000\n",
      "Class 2: 0.9768\n",
      "Class 3: 0.9488\n",
      "Class 4: 0.9410\n",
      "Class 5: 0.9285\n",
      "\n",
      "Epoch 4/10:\n",
      "Training Loss: 0.0146\n",
      "Validation Loss: 0.0136\n",
      "Validation MAP: 0.3411\n",
      "Validation F1-Score: 0.4026\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 1.0000\n",
      "Class 2: 0.9752\n",
      "Class 3: 0.9394\n",
      "Class 4: 0.9279\n",
      "Class 5: 0.9262\n",
      "\n",
      "Epoch 5/10:\n",
      "Training Loss: 0.0136\n",
      "Validation Loss: 0.0138\n",
      "Validation MAP: 0.3560\n",
      "Validation F1-Score: 0.4016\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 1.0000\n",
      "Class 2: 0.9809\n",
      "Class 3: 0.9779\n",
      "Class 4: 0.9652\n",
      "Class 5: 0.9566\n",
      "\n",
      "Epoch 6/10:\n",
      "Training Loss: 0.0128\n",
      "Validation Loss: 0.0130\n",
      "Validation MAP: 0.3718\n",
      "Validation F1-Score: 0.4523\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 1.0000\n",
      "Class 2: 0.9666\n",
      "Class 3: 0.9573\n",
      "Class 4: 0.9423\n",
      "Class 5: 0.9417\n",
      "\n",
      "Epoch 7/10:\n",
      "Training Loss: 0.0121\n",
      "Validation Loss: 0.0132\n",
      "Validation MAP: 0.3798\n",
      "Validation F1-Score: 0.4731\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 1.0000\n",
      "Class 2: 0.9841\n",
      "Class 3: 0.9791\n",
      "Class 4: 0.9791\n",
      "Class 5: 0.9605\n",
      "\n",
      "Epoch 8/10:\n",
      "Training Loss: 0.0113\n",
      "Validation Loss: 0.0131\n",
      "Validation MAP: 0.3849\n",
      "Validation F1-Score: 0.4572\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 1.0000\n",
      "Class 2: 0.9724\n",
      "Class 3: 0.9597\n",
      "Class 4: 0.9587\n",
      "Class 5: 0.9526\n",
      "\n",
      "Epoch 9/10:\n",
      "Training Loss: 0.0107\n",
      "Validation Loss: 0.0132\n",
      "Validation MAP: 0.3879\n",
      "Validation F1-Score: 0.4668\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 0.9842\n",
      "Class 2: 0.9721\n",
      "Class 3: 0.9628\n",
      "Class 4: 0.9456\n",
      "Class 5: 0.9456\n",
      "\n",
      "Epoch 10/10:\n",
      "Training Loss: 0.0100\n",
      "Validation Loss: 0.0137\n",
      "Validation MAP: 0.3899\n",
      "Validation F1-Score: 0.4763\n",
      "New best model saved as best_CNNClassifier_map_lastlayer.pth!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNNClassifier()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model, best_val_map = train_model( model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7d1032-8443-46a0-9623-726b3c2e5677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model being tested:  CNNClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54617711/ipykernel_1069390/3624373703.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_CNNClassifier_map_lastlayer.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 class-wise Average Precisions:\n",
      "Class 1: 0.9061\n",
      "Class 2: 0.8894\n",
      "Class 3: 0.8561\n",
      "Class 4: 0.8466\n",
      "Class 5: 0.8382\n",
      "Test MAP: 0.3320\n",
      "Test F1-Score: 0.4476\n"
     ]
    }
   ],
   "source": [
    "test_map, test_f1 = test_model(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04f0e4-426a-42f5-93e5-01a2b2e03910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
