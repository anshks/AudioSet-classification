{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92dc551a-92e9-4c76-b5c2-940332b54111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "print(\"imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50568fba-b746-4bc3-a2f0-e445caef3553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54426358/ipykernel_3159101/3713021574.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/train_rep.pt\")\n",
      "/state/partition1/job-54426358/ipykernel_3159101/3713021574.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/labels.pt\")\n",
      "/state/partition1/job-54426358/ipykernel_3159101/3713021574.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/test_rep.pt\")\n",
      "/state/partition1/job-54426358/ipykernel_3159101/3713021574.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/labels.pt\")\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/train_rep.pt\")\n",
    "y_train = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/train/labels.pt\")\n",
    "x_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/test_rep.pt\")\n",
    "y_test = torch.load(\"/scratch/gd2574/AudioSet-classification/Data/test/labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2538d-2a51-4c14-a349-8db6323d2a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c24d15f-b877-4003-8160-5e41d06fe9ce",
   "metadata": {},
   "source": [
    "# Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54dea643-ba6b-48b7-8bc4-c4bb546d0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stratified_split(x_data, y_data, random_state=42):\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    indices = np.arange(len(y_data))\n",
    "    for train_idx, val_idx in mskf.split(indices, y_data):\n",
    "        return train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316f09a-057e-42d5-8532-6a38d8a6be97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bf5cf19-9cb4-4200-8659-b59e3b793c4e",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d74bd43-f8bd-4c6d-951f-8cc09c326dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(y_true, y_pred):\n",
    "    n_classes = y_true.shape[1]\n",
    "    average_precisions = []\n",
    "    for i in range(n_classes):\n",
    "        y_true_class = y_true[:, i]\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        ap = average_precision_score(y_true_class, y_pred_class)\n",
    "        average_precisions.append(ap)\n",
    "    average_precisions_sorted = sorted(average_precisions, reverse=True)\n",
    "    # print(\"\\nTop 5 class-wise Average Precisions:\")\n",
    "    # for i, ap in enumerate(average_precisions_sorted[:5]):\n",
    "    #     print(f\"Class {i+1}: {ap:.4f}\")\n",
    "    \n",
    "    return np.mean(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca357837-b742-4adc-b00b-7429b9d6be39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0b5cea2-6835-4235-9ea5-a8b8dbdb89ab",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3e6a94-50d9-4ec4-973b-1332c042d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_model(model,optimizer,criterion, train_loader, val_loader,transform_type='mean', num_epochs=10):\n",
    "    print(f\"\\nTraining MLP with {transform_type} transformation\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_map = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float().to(device)\n",
    "                \n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_targets.extend(batch_y.cpu().numpy())\n",
    "        \n",
    "        val_predictions = np.array(val_predictions)\n",
    "        val_targets = np.array(val_targets)\n",
    "        val_map = calculate_map(val_targets, val_predictions)\n",
    "        val_f1 = f1_score(val_targets, (val_predictions > 0.5).astype(float), average='micro')\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "        print(f'Validation MAP: {val_map:.4f}')\n",
    "        print(f'Validation F1-Score: {val_f1:.4f}')\n",
    "        \n",
    "        if val_map > best_map:\n",
    "            best_map = val_map\n",
    "            torch.save(model.state_dict(), f'best_model_mlp_{transform_type}.pth')\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        print('-' * 50)\n",
    "    \n",
    "    return model, best_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca19a96-9fe1-469d-838f-6866263023cc",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e124fd6-a4db-4a9a-81af-4a038eb4dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning model testing...\n",
      "Error testing mean transform model: name 'MLPWithTransform' is not defined\n",
      "Error testing max transform model: name 'MLPWithTransform' is not defined\n",
      "Error testing append transform model: name 'MLPWithTransform' is not defined\n",
      "\n",
      "Final Test Results:\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_mlp_model(model, transform_type):\n",
    "    print(f\"\\nTesting model with {transform_type} transformation\")\n",
    "    \n",
    "    test_dataset = TensorDataset(x_test.float(), y_test.float())  \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=32, \n",
    "        shuffle=False,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    model_path = f'best_model_mlp_{transform_type}.pth'\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(f\"Successfully loaded model from {model_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find model file {model_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Move model to correct device\n",
    "    model = model.to(device)\n",
    "    model.eval()  \n",
    "    \n",
    "    test_predictions = []\n",
    "    test_targets = []  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader: \n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            test_predictions.extend(outputs.cpu().numpy())\n",
    "            test_targets.extend(batch_y.cpu().numpy())\n",
    "                \n",
    "    test_predictions = np.array(test_predictions)\n",
    "    test_targets = np.array(test_targets) \n",
    "    \n",
    "    test_map = calculate_map(test_targets, test_predictions)\n",
    "    test_f1 = f1_score(test_targets, (test_predictions > 0.5).astype(float), average=\"micro\")\n",
    "    \n",
    "    print(f\"Test MAP: {test_map:.4f}\")\n",
    "    print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return test_map, test_f1\n",
    "\n",
    "print(\"Beginning model testing...\")\n",
    "test_results = {}\n",
    "transforms = ['mean', 'max', 'append']\n",
    "\n",
    "for transform in transforms:\n",
    "    try:\n",
    "        model = MLPWithTransform(transform_type=transform)\n",
    "        test_map, test_f1 = test_model(model, transform)\n",
    "        test_results[transform] = {\n",
    "            'map': test_map,\n",
    "            'f1': test_f1\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing {transform} transform model:\", str(e))\n",
    "\n",
    "# Print final comparison\n",
    "print(\"\\nFinal Test Results:\")\n",
    "print(\"-\" * 50)\n",
    "for transform, metrics in test_results.items():\n",
    "    print(f\"{transform.capitalize()} Transform:\")\n",
    "    print(f\"  MAP: {metrics['map']:.4f}\")\n",
    "    print(f\"  F1:  {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7bd4a-3479-486c-be0a-e9cc5c1d7292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb2561-14d1-4396-bc47-d6bbfbe2a906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d066abc-5743-42ea-aa9e-eb67c342615f",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94f4cedf-c25b-476f-8e5f-298014db734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithTransform(nn.Module):\n",
    "    def __init__(self, input_size=768, hidden_size=1024, num_classes=527, transform_type='mean'):\n",
    "        super(MLPWithTransform, self).__init__()\n",
    "        self.transform_type = transform_type\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size // 2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(hidden_size // 2, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def transform_sequence(self, x):\n",
    "        # x shape: (batch_size, seq_len, features)\n",
    "        if self.transform_type == 'mean':\n",
    "            return torch.mean(x, dim=1)  # Average across sequence length\n",
    "        elif self.transform_type == 'max':\n",
    "            return torch.max(x, dim=1)[0]  # Max across sequence length\n",
    "        elif self.transform_type == 'append':\n",
    "            # Flatten the input\n",
    "            flattened_x = x.view(x.size(0), -1).numpy()\n",
    "            selector = SelectKBest(f_classif, k=1000)\n",
    "            selected_x = selector.fit_transform(flattened_x, y_train.numpy())\n",
    "            selected_x = torch.tensor(selected_x)\n",
    "            return selected_x #x.view(x.size(0), -1)\n",
    "            # return x[:, 0, :]  # Take first timestep features\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown transform type: {self.transform_type}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transform_sequence(x)  # Transform the sequence\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d5301-20ec-4060-9f66-e4fd5b11f539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abd375-9e16-4ddf-9558-5ab360f314ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64a6e107-8b82-49aa-a1ee-9af804d1dc6e",
   "metadata": {},
   "source": [
    "# lessgooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e82f9516-9f56-414d-a552-d3bdc5a38bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 20550\n",
      "Training samples: 16440\n",
      "Validation samples: 4110\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "learning_rate= 0.001\n",
    "num_epochs = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x_train_float = x_train.float()\n",
    "y_train_float = y_train.float()\n",
    "full_dataset = TensorDataset(x_train_float, y_train_float)\n",
    "total_size = len(full_dataset)\n",
    "\n",
    "# USING STRATIFIED SPLITS\n",
    "train_indices, val_indices = create_stratified_split(x_train_float, y_train_float.numpy())\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "train_loader = DataLoader(train_dataset,batch_size=32,  shuffle=True, pin_memory=True if torch.cuda.is_available() else False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32,pin_memory=True if torch.cuda.is_available() else False)\n",
    "print(f\"Total samples: {len(full_dataset)}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "transforms = ['mean', 'max', 'append']\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d31af8b-96ab-43aa-a38f-6efd54d7d249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP with mean transformation\n",
      "\n",
      "Epoch 1/2:\n",
      "Training Loss: 0.1396\n",
      "Validation Loss: 0.0206\n",
      "Validation MAP: 0.1016\n",
      "Validation F1-Score: 0.2114\n",
      "New best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 2/2:\n",
      "Training Loss: 0.0201\n",
      "Validation Loss: 0.0167\n",
      "Validation MAP: 0.2181\n",
      "Validation F1-Score: 0.3129\n",
      "New best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training MLP with max transformation\n",
      "\n",
      "Epoch 1/2:\n",
      "Training Loss: 0.1376\n",
      "Validation Loss: 0.0230\n",
      "Validation MAP: 0.0267\n",
      "Validation F1-Score: 0.1849\n",
      "New best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 2/2:\n",
      "Training Loss: 0.0228\n",
      "Validation Loss: 0.0203\n",
      "Validation MAP: 0.0811\n",
      "Validation F1-Score: 0.2297\n",
      "New best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training MLP with append transformation\n",
      "Error training with append transform: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
      "\n",
      "Final Results:\n",
      "mean transform - Best MAP: 0.2181\n",
      "max transform - Best MAP: 0.0811\n"
     ]
    }
   ],
   "source": [
    "for transform in transforms:\n",
    "    try:\n",
    "        model = MLPWithTransform(transform_type=transform)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        model, best_map = train_mlp_model(model,optimizer,criterion,train_loader, val_loader, transform_type=transform, num_epochs=num_epochs)\n",
    "        results[transform] = {'model': model, 'best_map': best_map}\n",
    "    except Exception as e:\n",
    "        print(f\"Error training with {transform} transform:\", str(e))\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "for transform, result in results.items():\n",
    "    print(f\"{transform} transform - Best MAP: {result['best_map']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d942b1a3-0321-4c1f-a2f3-b75b3e31b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model with mean transformation\n",
      "Successfully loaded model from best_model_mlp_mean.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54426358/ipykernel_3159101/3848944109.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAP: 0.0372\n",
      "Test F1-Score: 0.1516\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing model with max transformation\n",
      "Successfully loaded model from best_model_mlp_max.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54426358/ipykernel_3159101/3848944109.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAP: 0.0085\n",
      "Test F1-Score: 0.1570\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing model with append transformation\n",
      "Successfully loaded model from best_model_mlp_append.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54426358/ipykernel_3159101/3848944109.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAP: 0.2752\n",
      "Test F1-Score: 0.3890\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for transform in transforms:\n",
    "    test_mlp_model(model,transform_type=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f0152-6b42-48fd-9ac8-faa25eedf4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
